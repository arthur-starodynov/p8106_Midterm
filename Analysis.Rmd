---
title: "Analysis"
author: "Arthur Starodynov, Ekaterina Hofrenning, Lauren Lazaro"
date: "2024-03-24"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(caret)
library(mgcv)
library(earth)
library(leaps)
```

# Load in the data and explore the data. 

```{r}
load("data/recovery.Rdata")
head(dat)
set.seed(2024)
```

```{r}
library(summarytools)
st_options(plain.ascii = FALSE,
           style = "rmarkdown",
           dfSummary.silent = TRUE,
           footnote = NA,
           subtitle.emphasis = FALSE)

dfSummary(data[,-1])


```

```{r}
data <- dat %>%
  select(-id)   # removing the id variable from the data 
set.seed(2024)


tRows <- createDataPartition(dat$recovery_time, p = 0.7, list = FALSE)
# training data
data_train <- data[tRows, ]
x <- model.matrix(recovery_time~.,data)[tRows,-1]
y <- data$recovery_time[tRows]

#Test data
data_test <- data[-tRows, ]
x2 <- model.matrix(recovery_time~.,data)[-tRows,-1]
y2 <- data$recovery_time[-tRows]
```


# Exploring the data set : 

```{r}
data_train_viz <- data_train %>%
  mutate(study = case_when( # turn study (character variable) into a numeric variable
    study == "A" ~ 1,
    study == "B" ~ 2,
    study == "C" ~ 3))
non_numeric_cols <- sapply(data_train_viz, function(x) !is.numeric(x))
# Convert non-numeric columns to numeric
data_train_viz[, non_numeric_cols] <- lapply(data_train_viz[, non_numeric_cols], as.numeric)
```

```{r, warning=FALSE, message=FALSE}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x = data_train_viz[ ,1:14],
            y = data_train_viz[ ,15],
            plot = "scatter",
            span = .5,
            labels = c("Predictors (Xs)", "COVID-19 Recovery Time (Y)"),
            main = "Figure 1. Lattice Plot",
            type = c("p", "smooth"))
```




# Training models

Training Various models to see which will perform the best. 

LGM: 
```{r}
set.seed(2024)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5) # Using the best rule 
linear_model <- train(recovery_time ~ ., 
               data = data_train,
               method = "lm", 
               trControl = ctrl)
summary(linear_model)



```

Finding the RMSE: 

```{r}
linear_pred <- predict(linear_model, newdata = data_test)
linear_rmse <- sqrt(mean((linear_pred - data_test$recovery_time)^2))
linear_rmse

```

We can see that the RMSE is 19.858 for the Generalized linear model. 


## Lasso Model 

```{r}
set.seed(2024)
lasso_model <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-1, 5, length = 100))),
                   trControl = ctrl)

plot(lasso_model, xTrans = log)
tuning_param <- lasso_model$bestTune
coef(lasso_model$finalModel, lasso_model$bestTune$lambda)
```

Finding RMSE of the Lasso model: 

```{r}
lasso_pred <- predict(lasso_model, newdata = x2)
lasso_rmse <- sqrt(mean((lasso_pred - data_test$recovery_time)^2))
lasso_rmse

```


## PLS model

```{r}
set.seed(2024)
pls_model <- train(x, y,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:17),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))
print(plot(pls_model))

```


Finding the RMSE

```{r}
pls_pred <- predict(pls_model, newdata = x2)
pls_rmse <- sqrt(mean((pls_pred - data_test$recovery_time)^2))
pls_rmse
```


## Elastic net model

```{r}
set.seed(2024)
enet_model <- train(x, y, 
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                         lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl)
print(plot(enet_model))
```


Finding the RMSE 

```{r}
enet_pred <- predict(enet_model, newdata = x2)
enet_rmse <- sqrt(mean((enet_pred - data_test$recovery_time)^2))
enet_rmse
```


## MARS model 

Resampling the data by encoding dummy variables to be able to use a MARS model. 

```{r}
set.seed(2024)
df_dummies <- data.frame(model.matrix(~ . - 1, data = dat[, c("gender", "race", "smoking", "hypertension", "diabetes", "vaccine", "severity", "study")]),
                         age = dat$age,
                         height = dat$height,
                         weight = dat$weight,
                         bmi = dat$bmi,
                         SBP = dat$SBP,
                         LDL = dat$LDL,
                         recovery_time = dat$recovery_time)

data_mars <- df_dummies

#training
data_train_mars <- data_mars[tRows, ]
mars_x <- model.matrix(recovery_time~.,data_mars)[tRows,-1]
mars_y<- data_mars$recovery_time[tRows]

# test
data_test_mars <- data_mars[-tRows, ]
## matrix of predictors
mars_x2 <- model.matrix(recovery_time~.,data_mars)[-tRows,-1]
## vector of response
mars_y2 <- data_mars$recovery_time[-tRows]
```

Using newly created data to train a MARS model. 

```{r}
set.seed(2024)
mars_grid <- expand.grid(degree = 1:3, 
                         nprune = 2:17) 

mars_model <- train(mars_x, mars_y,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl)
print(plot(mars_model))
```

Find the RMSE 

```{r}
mars_pred <- predict(mars_model, newdata = mars_x2) 
mars_rmse <- sqrt(mean((mars_pred - data_test_mars$recovery_time)^2))
mars_rmse

```